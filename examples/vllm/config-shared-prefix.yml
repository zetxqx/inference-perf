load:
  type: constant
  interval: 15
  stages:
  - rate: 1
    duration: 30
  - rate: 2
    duration: 30
api:
  type: completion
server:
  type: vllm
  model_name: HuggingFaceTB/SmolLM2-135M-Instruct
  base_url: http://0.0.0.0:8000
  ignore_eos: true
tokenizer:
  pretrained_model_name_or_path: HuggingFaceTB/SmolLM2-135M-Instruct
data:
  type: shared_prefix
  shared_prefix:
    num_groups: 10                # Number of distinct shared prefixes
    num_prompts_per_group: 10     # Number of unique questions per shared prefix
    system_prompt_len: 100        # Length of the shared prefix (in tokens)
    question_len: 50              # Length of the unique question part (in tokens)
    output_len: 50                # Target length for the model's generated output (in tokens)
metrics:
  type: prometheus
  prometheus:
    url: http://localhost:9090
    scrape_interval: 15
report:
  request_lifecycle:
    summary: true
    per_stage: true
    per_request: true